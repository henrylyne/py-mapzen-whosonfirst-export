#!/usr/bin/env python

import sys
import os.path
import geojson
import logging

"""
Simple - as in dump all the openvenues stuff to flatfiles using a concordances (sqlite) db to not reassign MZ IDs to things:

/usr/local/bin/mzg-exportify -d /usr/local/mapzen/gazetteer -s openvenues -c /usr/local/mapzen/gazetteer-concordances/concordances-mzid-mzpuid.csv --skip -v /usr/local/mapzen/openvenues-data/*_*.geojson

Detailed - as in these should maybe all be smushed together in a separate shell script or something:

/usr/local/bin/woeisthat-import -d concordances-mzid-mzpuid.db -s csv concordances-mzid-mzpuid.csv

/usr/local/bin/mzg-exportify -d /usr/local/mapzen/gazetteer -s openvenues -c /usr/local/mapzen/gazetteer-concordances/concordances-mzid-mzpuid.csv --skip -v /usr/local/mapzen/openvenues-data/*_*.geojson

/usr/local/bin/mzg-concordify -s /usr/local/mapzen/gaztteer -f 'mz:puid' -c /usr/local/mapzen/gazetteer-concordances/concordances-mzid-mzpuid.csv

"""

def export_feature(exporter, feature, args, options):

    if options.verbose:	
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    exporter.export_feature(feature, **args)

if __name__ == '__main__':
    
    import sys
    import optparse
    import multiprocessing

    opt_parser = optparse.OptionParser()

    opt_parser.add_option('-d', '--dest', dest='dest', action='store', default=None, help='Where to write export files')
    opt_parser.add_option('-s', '--source', dest='source', action='store', default=None, help='Source to export')
    opt_parser.add_option('-c', '--concordances', dest='concordances', action='store', default=None, help='PUID <--> Mapzen ID lookup database')
    opt_parser.add_option('--place-type', dest='place', action='store', default=None, help='A particular place type (for a source) to export')
    opt_parser.add_option('--multi-processing', dest='multi', action='store_true', default=False, help='Use multiple processors (default is False)')
    opt_parser.add_option('--line-delimited', dest='line', action='store_true', default=False, help='GeoJSON is line-delimited (default is False)')
    opt_parser.add_option('--skip-existing', dest='skip', action='store_true', default=False, help='Do not overwrite existing files (default is False)')

    opt_parser.add_option('--debug', dest='debug', action='store_true', default=False, help='Enable debugging (default is false)')
    opt_parser.add_option('--verbose', dest='verbose', action='store_true', default=False, help='Be chatty (default is false)')
    options, args = opt_parser.parse_args()

    if options.verbose:	
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    obj_args = {
        'debug': options.debug
        }
    
    if options.concordances:
        obj_args['concordances'] = options.concordances

    export_args = {
        'skip_existing': options.skip
        }

    dest = os.path.abspath(options.dest)

    if options.source == 'openvenues':

        import mapzen.gazetteer.export.openvenues
        e = mapzen.gazetteer.export.openvenues.exporter(dest, **obj_args)

    elif options.source == 'simplegeo':
        import mapzen.gazetteer.export.simplegeo

        e = mapzen.gazetteer.export.simplegeo.exporter(dest, **obj_args)

    elif options.source == 'quattroshapes':

        import mapzen.gazetteer.export.quattroshapes

        if options.place == 'country' or options.place == 'adm0':
            e = mapzen.gazetteer.export.quattroshapes.adm0_exporter(dest, **obj_args)

        elif options.place == 'region' or options.place == 'adm1':
            e = mapzen.gazetteer.export.quattroshapes.adm1_exporter(dest, **obj_args)

        elif options.place == 'county' or options.place == 'adm2':
            e = mapzen.gazetteer.export.quattroshapes.adm2_exporter(dest, **obj_args)

        else:
            logging.error("Invalid place or missing placetype")
            sys.exit()


    else:
        logging.error("Unknown or invalid source to export")
        sys.exit()

    for file in args:

        path = os.path.abspath(file)
        logging.info("reading %s" % path)

        if options.multi:
            logging.debug("create new pool")
            pool = multiprocessing.Pool(processes=8)

        fh = open(path, 'r')

        if options.line:

            for ln in fh.readlines():

                try:
                    data = geojson.loads(ln)
                except Exception, e:
                    logging.error("failed to read ln, because %s" % e)
                    logging.debug(ln)
                    continue

                if options.multi:
                    pool.apply_async(export_feature, (e, data, export_args, options))
                else:
                    e.export_feature(data, **export_args)

        else:

            try:
                data = geojson.load(fh)
            except Exception, e:
                logging.error("failed to read %s, because %s" % (path, e))
                continue

            for f in data['features']:

                if options.multi:
                    pool.apply_async(export_feature, (e, f, export_args, options))
                else:
                    e.export_feature(f, **export_args)

        if options.multi:
            pool.close()
            pool.join()

    sys.exit()
